{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source https://www.pythonforthelab.com/blog/how-to-use-hdf5-files-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic saving and reading the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshay/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "arr = np.random.randn(1000)\n",
    "\n",
    "with h5py.File('random.hdf5', 'w') as f:\n",
    "    dset = f.create_dataset(\"default\", data=arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.1155833593559734\n",
      "3.657201953104082\n",
      "[-0.61642994 -0.50906164  1.64592415  0.56725858  0.06411687  0.65907973\n",
      "  1.2436992   0.20323535  0.88101301 -0.03446799  0.50091855 -0.19534449\n",
      " -1.4705829  -0.96633255  0.13376327]\n",
      "default\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('random.hdf5', 'r') as f:\n",
    "   data = f['default']\n",
    "   print(min(data))\n",
    "   print(max(data))\n",
    "   print(data[:15])\n",
    "   for key in f.keys():\n",
    "       print(key) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = h5py.File('random.hdf5', 'r')\n",
    "# data = f['default']\n",
    "# f.close()\n",
    "# print(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5009185459355459\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File('random.hdf5', 'r')\n",
    "data = f['default'][:]\n",
    "f.close()\n",
    "print(data[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selective reading from HDF5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5090616409706761\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('random.hdf5', 'r') as f:\n",
    "   data_set = f['default']\n",
    "   data = data_set[:10]\n",
    "\n",
    "print(data[1])\n",
    "#print(data_set[1]) # error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arr1 = np.random.randn(10000)\n",
    "arr2 = np.random.randn(10000)\n",
    "\n",
    "with h5py.File('complex_read.hdf5', 'w') as f:\n",
    "    f.create_dataset('array_1', data=arr1)\n",
    "    f.create_dataset('array_2', data=arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5py.File('complex_read.hdf5', 'r') as f:\n",
    "#     d1 = f['array_1']\n",
    "#     d2 = f['array_2']\n",
    "\n",
    "#     data = d2[d1>0] # wont work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of data with a for loop: 4882\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('complex_read.hdf5', 'r') as f:\n",
    "    d1 = f['array_1']\n",
    "    d2 = f['array_2']\n",
    "\n",
    "    data = d2[d1[:]>0]\n",
    "print('The length of data with a for loop: {}'.format(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of data with a for loop: 4882\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('complex_read.hdf5', 'r') as f:\n",
    "    d1 = f['array_1']\n",
    "    d2 = f['array_2']\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for i in range(len(d1)):\n",
    "        if d1[i] > 0:\n",
    "            data.append(d2[i])\n",
    "\n",
    "print('The length of data with a for loop: {}'.format(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selective writing to HDF5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.randn(100)\n",
    "\n",
    "with h5py.File('random.hdf5', 'w') as f:\n",
    "   dset = f.create_dataset(\"default\", (1000,))\n",
    "   dset[10:20] = arr[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.07396209e-01  6.31643058e-01 -6.13761108e-01  1.08416731e+00\n",
      " -7.11668459e-01  2.54749148e-01  1.83865260e+00  7.74822744e-01\n",
      " -7.68735208e-01 -1.10934281e+00 -1.47762630e+00 -5.55610100e-01\n",
      "  3.17339507e-02 -7.69294869e-01  1.78294925e+00 -1.57473234e+00\n",
      " -9.41925180e-01  2.08802876e+00  1.04287200e+00 -4.10421024e-01\n",
      " -1.96290813e+00 -4.64331019e-01  3.74820404e-01  5.44994939e-01\n",
      " -9.91450073e-01 -6.41072896e-01 -1.49945534e+00 -6.91575424e-01\n",
      " -1.38145757e-01 -2.88435138e-02  4.56048471e-01  8.39027790e-01\n",
      "  1.69118038e+00 -2.35105212e+00  8.98509875e-01 -1.29156044e+00\n",
      " -1.82945796e+00  7.90489476e-01  1.22316018e+00 -4.87344320e-01\n",
      " -9.27412600e-01 -1.38977012e-01  1.04517895e-01 -1.93829491e+00\n",
      "  7.12960402e-01  1.32260819e+00 -2.04726678e-02  4.70621581e-01\n",
      " -9.29891703e-01  8.54203166e-01  9.99007400e-01 -1.00200014e+00\n",
      "  1.54859960e+00 -1.06088152e-01 -8.66807403e-02 -5.00529634e-02\n",
      "  1.46207189e+00 -8.44777521e-01  7.94372985e-01  1.83292850e+00\n",
      "  2.19205366e+00  3.83501492e-01 -8.95855817e-01 -1.41186144e-01\n",
      " -1.20034325e+00 -5.23464182e-01 -6.39585976e-03 -1.60856199e+00\n",
      "  1.54707572e+00 -1.17571052e+00  1.32323754e+00  2.48740212e-01\n",
      "  5.15725611e-01 -1.97179267e-01  8.33219976e-01 -8.59696667e-03\n",
      "  3.63757761e-01 -1.37016269e+00  1.08763879e+00  2.19721832e-02\n",
      " -2.08119962e-01  9.89241208e-01  6.45109817e-01  1.74540246e+00\n",
      "  6.24441182e-01 -1.01774498e+00 -8.57104259e-01 -3.94384802e-01\n",
      "  1.26217629e+00 -1.06346477e+00  8.24045452e-01 -1.59893154e+00\n",
      " -2.06531723e+00 -2.56341820e-01 -8.90490377e-01  1.05297721e+00\n",
      " -4.28723209e-01 -5.72281152e-01  5.04152339e-01 -1.11496670e+00\n",
      "  1.23866129e+00 -5.19277530e-01  4.84044492e-02  1.36475670e+00\n",
      " -1.35408042e+00  1.37713879e-01 -1.77720714e-01 -5.75541264e-01\n",
      "  7.61727666e-01  1.90528171e-01  1.03545128e+00  5.23099057e-01\n",
      " -4.81901887e-01 -4.78869886e-01  1.28530991e+00 -8.35877028e-01\n",
      " -5.21745873e-01  9.31754276e-01 -3.01887234e-01  6.67852089e-02\n",
      " -6.85337485e-01 -8.25223238e-01  2.07455392e+00 -5.89884146e-01\n",
      "  1.68122451e+00  1.61585043e+00 -8.97862096e-01 -3.01519920e-01\n",
      " -1.40636073e-01 -1.58861826e+00  1.88217103e+00  8.54344098e-01\n",
      " -3.02732382e-01 -9.69115534e-01 -3.71413553e-01  4.50721898e-01\n",
      "  5.09067958e-01  1.17664860e+00  4.37239986e-01 -2.13699386e-01\n",
      "  5.69928938e-01  8.64627709e-01  9.67202825e-01  3.92911287e-01\n",
      " -9.31624161e-01 -3.99780264e-01  8.33928357e-01 -1.32757415e+00\n",
      " -7.29211113e-01 -1.40329148e+00 -5.47491447e-01 -1.06119651e+00\n",
      "  3.56195174e-02 -3.99664291e-01  5.64357096e-01 -4.31334061e-01\n",
      "  1.45530870e+00 -3.66010144e-01 -3.88688250e-01 -1.35503368e-01\n",
      "  2.35996071e-01  7.24384730e-01  1.30582780e+00  4.10342725e-01\n",
      " -6.76512389e-01 -3.44170967e-01  7.29807671e-02  1.21963410e+00\n",
      "  4.93484001e-01  1.91189877e-01  1.35309917e+00 -1.08305347e-01\n",
      "  1.64062231e+00 -6.06058748e-01  9.27711517e-02 -5.43057141e-01\n",
      " -1.50270904e+00  1.11390732e+00  8.22762689e-01  2.49320975e+00\n",
      "  1.45819474e+00 -1.57868294e-01  1.42566798e+00  2.64243774e-01\n",
      "  5.97869506e-01  9.04204798e-01 -1.51834685e+00  1.75332298e+00\n",
      "  4.89670653e-02 -2.46069220e+00  2.81957340e-01 -1.67652335e+00\n",
      " -1.56167876e+00 -2.11250108e+00 -3.88141158e-02 -6.19242961e-01\n",
      "  8.74085170e-01  1.30561777e-01  1.77919364e+00 -5.33452162e-02\n",
      " -9.43728065e-01  6.36402908e-02  8.56582282e-02 -2.33174190e-01\n",
      "  5.05800503e-02  5.75222236e-01  3.06158036e-01  2.38099460e+00\n",
      "  4.65287933e-01  1.51726087e+00 -2.43557787e-01  1.72568724e+00\n",
      "  2.57327446e-02 -8.38402445e-01 -1.01076809e+00  1.02401571e+00\n",
      " -1.05739732e+00 -9.05512485e-01 -2.74053918e+00  6.78373870e-01\n",
      "  3.64536853e-01 -1.36606936e+00 -7.35889657e-01 -7.87670622e-01\n",
      "  6.92301496e-01 -2.97830271e-01  8.52389973e-01  4.70795176e-01\n",
      "  3.06800160e-01 -1.08688994e+00 -6.61272310e-01 -1.83866012e+00\n",
      " -8.75592287e-01 -1.41876689e+00 -2.72661506e+00 -8.61414584e-01\n",
      "  2.54977921e-01 -1.11291715e+00  4.31553564e-01 -9.74984507e-03\n",
      " -1.56166842e+00 -7.61194923e-01  4.32417913e-03 -3.02680535e-01\n",
      "  1.33605718e+00 -1.03927643e+00 -1.02921267e+00 -2.77626997e-01\n",
      " -1.68765984e+00  2.00655838e+00  1.09595118e-01  2.14231316e+00\n",
      "  1.31131243e+00 -1.92680920e+00  9.45517535e-01  1.96928846e+00\n",
      "  1.12152283e+00  9.12286450e-01 -1.17566052e+00 -1.04689156e-01\n",
      " -1.35839215e-01 -6.99908290e-01  4.16570001e-01 -1.14479471e-02\n",
      "  2.51888755e-01 -6.19985566e-01 -3.65643873e-01 -8.13986453e-01\n",
      "  3.50841099e-01  8.05171172e-01 -8.23317835e-01  8.41734865e-02\n",
      "  4.33497361e-01 -4.34547275e-01 -6.59954688e-01 -1.55377299e+00\n",
      "  1.00091395e+00  2.60086665e+00  5.59135751e-01  1.94554082e+00\n",
      "  4.63069216e-01 -1.67612709e+00  2.15173480e-01  1.75765338e+00\n",
      " -5.47537157e-01  7.81981312e-01  4.23849350e-01  2.13157845e+00\n",
      " -5.94101949e-02  1.45933773e+00 -2.74664370e-01 -1.12318848e-03\n",
      " -7.23516551e-01  4.70501225e-01 -4.72826651e-01 -1.33526654e-01\n",
      " -1.89365190e+00 -1.88332253e+00 -9.42300121e-01 -4.04113978e-01\n",
      " -5.62493740e-01 -2.34628408e-01  1.25080869e-02  2.17115520e+00\n",
      " -8.88493108e-01  6.23485148e-01 -1.23822349e+00  5.16179425e-01\n",
      "  1.70353017e-01  7.43293908e-02 -1.03670502e+00 -3.75298637e-01\n",
      " -1.75894653e-02 -1.00276323e+00 -4.21394432e-01 -4.97452807e-01\n",
      "  2.10602981e+00 -1.06782361e+00  1.04164419e+00 -4.38965133e-01\n",
      "  6.51708724e-01 -1.32643681e+00  5.66081523e-01  2.90754836e-01\n",
      "  1.71703666e+00  1.93087055e+00 -1.72305064e-01 -1.03807428e+00\n",
      "  2.08444916e-01  5.75443674e-01  9.24313442e-01  7.41465687e-01\n",
      " -2.23660332e+00  5.74799434e-01 -2.75591036e-01  7.90263984e-01\n",
      "  6.93086647e-01 -1.43733406e-01  1.63307932e-01  7.10060702e-01\n",
      "  1.13107077e+00  6.19643921e-01  1.27833651e+00 -1.49084203e+00\n",
      "  1.04221443e+00 -1.19909171e+00 -5.34497191e-01 -7.01652260e-01\n",
      "  6.38925440e-01 -6.67552359e-01  5.54840979e-01 -9.58125516e-01\n",
      "  1.26503409e+00 -4.16698612e-01 -6.81758001e-01 -2.70101429e-01\n",
      "  3.89434654e-01 -2.80973254e+00  6.33213587e-03  2.75048501e-02\n",
      " -1.49130747e-01  7.57614115e-01 -3.90671292e-01 -8.64249289e-02\n",
      "  3.27684459e-01  6.31500426e-01  4.52554416e-01  8.99237032e-01\n",
      " -4.43615053e-01  8.97041646e-01  5.94394369e-01 -7.17702346e-01\n",
      " -1.08985541e+00  2.46732368e-02  6.02234344e-01 -2.71951633e-01\n",
      " -1.44711517e-01 -1.38108917e+00 -2.16987383e+00 -6.34626528e-01\n",
      " -4.01883938e-01 -8.86180831e-01  1.09979328e-01  3.39291835e-01\n",
      "  4.58620856e-01 -1.41358958e+00  6.79913038e-01  5.88034067e-01\n",
      "  7.76266716e-01  1.84140721e+00  2.13150896e+00  8.24559186e-01\n",
      " -1.09881611e+00  1.12892791e+00  1.46688080e-01 -4.82720358e-01\n",
      "  3.35795959e-01 -1.41687214e+00  1.01637799e+00  1.21275662e-01\n",
      "  2.49609572e-01 -8.01758390e-01  3.00597425e-01  2.43033233e-01\n",
      "  1.07010966e+00 -7.01593323e-02 -2.44981547e-01  2.44863795e-01\n",
      "  4.12256571e-03  5.12827751e-01  3.62641779e-01  2.99018432e-01\n",
      "  7.49216337e-01 -9.31561290e-01 -5.22241442e-01 -1.33403388e-01\n",
      "  1.64115801e+00  1.72468065e+00  2.28985367e-01 -7.18487706e-01\n",
      "  1.06344675e-01  1.46541805e+00 -2.36588307e+00  5.07125947e-01\n",
      " -2.50471713e-01 -8.09700966e-02  1.50182776e+00  1.43484496e+00\n",
      " -1.17697696e+00  7.96594354e-01 -7.62243310e-01 -7.88203525e-01\n",
      "  8.00148598e-01  2.33654348e-01 -1.73880526e+00  1.75506350e+00\n",
      " -8.43599057e-01  6.52568622e-01 -5.40815741e-01  6.48156067e-01\n",
      " -5.99121680e-02 -9.82888603e-01  9.05369254e-01 -1.65223882e-01\n",
      " -1.32100278e+00  7.12566456e-01  1.07346458e+00 -1.26076238e+00\n",
      "  1.19854690e-01  5.32889556e-01  9.72034706e-01 -6.23349214e-01\n",
      "  2.59736355e-02  8.00876548e-01  4.88568974e-01  8.44331016e-02\n",
      " -7.50426450e-01  1.81969465e+00 -7.99000871e-01  1.72221322e-01\n",
      " -3.19564295e-01 -1.32230284e+00 -8.03906759e-01  3.50980603e-01\n",
      "  5.83328739e-01 -7.16117951e-01 -7.74744689e-01  1.11592147e+00\n",
      "  1.16725164e+00  3.75731353e-01  2.04245114e-01 -7.67243493e-03\n",
      " -1.64900078e-01  6.06763208e-01  9.54836206e-01  1.67070674e+00\n",
      "  4.12782462e-01  1.67478867e-02 -1.05143781e+00 -1.02102370e+00\n",
      "  9.15197181e-02 -8.79005704e-01 -1.88439722e-01  1.75399650e+00\n",
      " -1.63180123e-01 -4.98462475e-01  2.91990135e-01 -1.25199459e-01\n",
      " -7.90380980e-01  1.15383087e+00  2.51635749e-01 -1.21743018e-01\n",
      "  1.38145822e-01  8.89082173e-01  3.85139349e-01 -2.70599479e-01\n",
      "  2.44389719e-01 -3.28477602e-01 -6.00275432e-01 -4.96353494e-01\n",
      "  1.30430657e+00 -8.52446266e-01 -8.48946696e-01 -1.13578477e-01\n",
      " -8.13523597e-01  9.05623509e-01 -1.06884984e-01  4.53366013e-02\n",
      "  1.35584941e+00 -2.51943394e+00  5.90127934e-01  1.64669615e+00\n",
      "  1.47597406e+00  9.03605024e-02  2.21906075e+00 -1.06519165e+00\n",
      " -1.45946019e+00  1.64515605e+00  1.44351473e+00  2.56267797e-01\n",
      "  2.77958425e-01  5.28593189e-01 -1.26044886e-01  8.05942323e-02\n",
      " -2.14286279e+00 -7.57573117e-01 -4.02991350e-01 -8.72356003e-01\n",
      " -3.78654158e-02 -7.14518369e-01 -4.46235924e-01 -4.70619540e-01\n",
      " -2.16053606e-01 -4.67096286e-01 -8.11479002e-01 -1.38102751e+00\n",
      "  6.97215666e-01  4.60886591e-01 -1.08234657e-01 -4.42177881e-01\n",
      " -3.94409606e-01 -1.45408187e+00  3.01776331e-01  1.69453817e-01\n",
      " -7.82534682e-01  3.65979458e-02 -1.60138884e+00 -2.13855694e+00\n",
      " -7.19594719e-01 -4.29251641e-01  3.09637756e-01 -1.27752119e-01\n",
      " -9.69010494e-01  1.09686253e+00  2.14445244e-01 -9.67203189e-01\n",
      " -2.96886766e-01  2.31793439e-01  1.00393858e+00 -3.18473416e-01\n",
      "  1.53802248e+00  1.19383860e+00 -8.94249000e-01  5.35905783e-01\n",
      "  9.22631029e-02 -4.80006290e-01 -4.28537122e-01 -1.65201142e-01\n",
      "  1.03496607e+00 -9.49014149e-01  6.47967952e-01  3.33809725e-01\n",
      " -9.54722560e-01  7.92022720e-02 -8.96802324e-01 -9.61624180e-01\n",
      " -1.74635635e+00 -1.23656568e-01  1.24368279e+00 -2.50026958e-01\n",
      " -3.26901353e-01  6.20262168e-02 -1.29488083e+00  3.56450191e-01\n",
      "  9.61550968e-02 -5.56423269e-01  8.80439118e-01 -9.47616780e-01\n",
      "  1.79800697e-01  6.58293206e-01  7.29009472e-03 -1.01764482e-01\n",
      " -7.23706819e-01  1.21610229e+00  1.58201352e+00  4.24629437e-01\n",
      " -3.70993525e-01 -1.20708766e-01 -1.80517250e-01  9.11486196e-01\n",
      "  8.48965278e-02 -3.67727948e-01 -1.55987956e+00 -4.44139453e-01\n",
      "  8.23787445e-01  1.39464684e+00  1.54742889e-01 -5.61500993e-01\n",
      "  5.80983252e-01  3.33562416e-01 -1.34230291e+00 -2.46807271e-01\n",
      " -1.57732080e+00 -8.92583314e-01  6.15397443e-01 -3.27202552e-01\n",
      "  2.23777856e+00 -1.34017728e-01 -7.73942202e-01 -5.16986804e-01\n",
      "  3.76604237e-03 -1.25860354e+00 -1.87285049e+00 -9.23879632e-01\n",
      " -5.35190742e-02  2.18142920e+00  4.33249343e-01  2.62373164e-02\n",
      "  6.25344197e-01  1.13917134e+00  1.08162027e+00 -1.36827426e+00\n",
      "  1.02768715e+00 -8.27934722e-01 -4.42886190e-01 -1.33507584e+00\n",
      "  7.72778185e-01 -3.44855416e-01 -5.86912527e-01  1.66846648e-01\n",
      " -1.02230089e+00 -6.07039483e-01  2.31384005e-01  1.61461401e-01\n",
      " -7.85781606e-01  8.17815258e-01 -5.17493488e-02  3.64155808e-01\n",
      "  7.24764397e-01 -3.11097048e-01 -4.96807384e-01  1.49230320e-01\n",
      " -5.70098360e-01  1.99092778e+00 -9.58908416e-01 -2.51406722e-01\n",
      "  4.36957670e-01 -6.48399137e-01  6.70892393e-01 -8.37224748e-01\n",
      " -4.62994385e-01 -1.12533056e+00  4.48032163e-01 -1.53941833e-01\n",
      " -8.53374849e-01 -1.63926641e+00 -5.90298844e-01  7.42970462e-01\n",
      " -1.20842134e+00 -1.10940406e+00  8.39636806e-01 -2.44634633e+00\n",
      "  6.19400196e-01  2.82807805e-01 -1.10512687e-01 -4.40951956e-01\n",
      "  1.48076779e+00  5.64874040e-01  1.00777244e+00 -1.32017475e-01\n",
      " -2.23785673e-01  1.97164154e+00 -6.54662683e-01 -1.36284116e+00\n",
      "  1.87664293e+00 -2.92982012e-01  1.06830311e+00  3.74588972e-01\n",
      " -7.50225252e-01  7.86829535e-02  1.05653016e+00  1.71908308e+00\n",
      "  5.47799068e-02  2.52167714e-01  2.59715589e-01  2.28769748e-01\n",
      " -2.29116308e+00 -4.68091585e-01  2.26946591e+00  1.09409766e+00\n",
      "  1.46799696e+00 -2.84284334e-01  7.19084465e-02  2.29250410e-01\n",
      "  1.31985430e-01  4.93285168e-01  1.74175547e+00  2.19983605e-01\n",
      " -6.37778045e-01  1.93564174e+00  6.08084929e-01 -3.87259509e-01\n",
      "  2.52790777e-01 -7.72233634e-02  4.14610560e-02 -6.93297543e-01\n",
      "  1.33146113e+00  8.80252971e-01 -6.21852723e-01  9.76293584e-01\n",
      "  1.09536861e+00 -1.43931667e+00 -8.43356425e-01  1.32788101e+00\n",
      "  5.02291786e-01 -1.27474601e-02 -8.59145409e-04  1.11214841e+00\n",
      " -5.77068178e-01 -4.91426610e-02  1.24569601e+00  4.65910791e-02\n",
      " -1.62388957e-01 -1.09963095e+00  7.33144058e-01  8.69759199e-01\n",
      " -1.01233640e+00 -1.06792790e+00  3.19311501e-01 -7.01849830e-01\n",
      "  3.45654603e-01  1.67094145e+00  1.64684618e+00  5.13280858e-01\n",
      " -2.54630402e-01 -8.21355257e-01 -1.08386900e+00 -6.92028934e-01\n",
      "  1.75674301e-01  1.95887161e-01  9.65952651e-01 -8.73363582e-01\n",
      "  1.61165093e-01 -4.65471744e-01  8.28458697e-01  7.35345942e-01\n",
      " -2.53570857e-01 -1.00460287e+00  6.47254702e-01 -1.24472203e+00\n",
      " -2.71932686e-02  2.03732038e+00  4.48247886e-01  1.74319224e-01\n",
      "  6.66646830e-01  5.99970610e-01 -1.02291550e+00 -1.80878154e+00\n",
      " -1.19373316e-01 -5.42273328e-01  6.43600710e-01 -1.99845206e+00\n",
      "  7.49869700e-03  1.64635217e+00  5.73938189e-01 -2.12211315e-01\n",
      "  9.51099887e-01 -2.03871824e+00  1.65795131e+00 -1.31577873e+00\n",
      "  3.62180125e-01 -2.00684863e+00 -1.26242119e+00  7.65568937e-02\n",
      " -3.98721744e-02 -6.48057620e-01 -1.08124459e+00 -4.34004186e-01\n",
      "  4.51316581e-01  2.47850564e-01 -8.78118615e-01  3.22025793e-01\n",
      "  2.19340591e-01  6.38065792e-02 -9.94466571e-01  4.59005479e-01\n",
      " -7.88395985e-01 -1.06450587e+00 -4.93371884e-02 -1.41277933e+00\n",
      " -1.28171633e+00  6.30958292e-01  2.02929751e+00  1.04236761e-01\n",
      "  1.65422762e+00 -1.72713175e+00 -1.24026757e+00  1.82062196e+00\n",
      "  7.18860958e-01 -1.10763240e-01  6.01066100e-01 -3.35586466e-02\n",
      "  1.38901639e+00  4.50609846e-02 -1.17500142e-01  1.38369691e+00\n",
      "  3.96442341e-01 -2.51626956e-01  9.23796185e-01 -1.71136905e-01\n",
      "  6.92840664e-01 -1.84196353e+00 -1.06115274e+00  1.83037050e-01\n",
      " -4.57784984e-01 -1.11627665e+00 -7.95223059e-01  6.87362899e-01\n",
      " -5.88767291e-01  4.11939027e-01 -2.11562956e+00 -5.98809073e-01\n",
      "  1.86341979e+00 -9.38529730e-01 -8.38065689e-01 -2.36197098e-01\n",
      " -2.54510934e-01 -7.60479198e-01 -7.28572842e-01  5.10920141e-01\n",
      "  1.65207465e-01  7.29503198e-02  1.06802735e-01 -2.63803602e+00\n",
      " -1.09430523e+00 -7.91884682e-01  5.63049918e-01 -2.03107316e-01\n",
      "  1.63190538e+00 -7.17534179e-01 -1.10767095e+00 -1.47665379e+00\n",
      "  1.98359286e-01  1.02165614e+00 -1.74955197e-01 -2.90630178e-01\n",
      " -8.64182361e-01  9.46938408e-01 -1.24240200e+00 -5.95899827e-01\n",
      " -1.04569418e+00  7.66627954e-01 -4.21998856e-01  1.59400107e-02\n",
      "  8.41303589e-02  8.61554031e-01 -2.92179805e-01 -1.19405929e+00\n",
      "  6.19526098e-01  2.00472038e+00  2.49267158e-01 -7.70062512e-01\n",
      " -1.46641029e+00  6.23307381e-01  1.56789279e+00 -5.28005506e-01\n",
      " -5.50214899e-01  6.47643549e-01 -6.81234092e-01 -7.69912695e-01\n",
      " -3.12202918e-01  4.10691074e-01  2.95861704e-01  6.10837015e-01\n",
      " -2.87767766e-01 -5.65584542e-01 -1.61977479e+00  1.79224673e-01\n",
      "  6.38104819e-01  1.30547345e+00 -6.11080768e-01 -2.39999566e-01\n",
      " -1.68321483e+00 -8.34520703e-01  1.08302523e+00 -1.24098870e+00\n",
      "  9.15418756e-01 -4.80612535e-01 -7.83711038e-02  9.32267816e-01\n",
      "  9.31555977e-01 -4.11002988e-01  6.30315911e-01  1.34089461e+00\n",
      "  8.65509467e-01  1.05500702e+00 -1.38367917e+00 -2.56159052e-01\n",
      "  1.10169595e+00 -2.11104383e+00  1.03639728e+00  1.31912450e+00\n",
      " -1.22775145e+00 -4.45848127e-01 -1.37192164e-01  1.46439222e+00\n",
      " -1.05793037e+00 -2.01342517e+00 -7.53552465e-01  5.18021090e-01\n",
      "  1.04975722e+00  2.92696260e-01 -6.42537784e-01 -7.15505120e-01\n",
      "  4.91549324e-01 -1.70881318e-01  2.27303472e-01  3.37216112e-01\n",
      "  6.36925289e-03  1.09752628e+00 -1.16762315e+00 -1.16011831e+00\n",
      " -2.41186840e-01 -1.84760385e+00 -7.03433165e-01 -1.04072635e+00\n",
      "  1.31718418e+00 -1.45776877e+00 -1.24779987e+00 -2.28666956e-01\n",
      " -4.99746540e-01  2.68657244e-01  1.66296936e+00 -6.26667268e-01\n",
      "  7.92468717e-01  4.28738807e-02 -5.36047038e-01  8.14742586e-01\n",
      " -9.16041585e-01  3.12438505e-01 -1.54401502e+00 -3.05909806e-01\n",
      "  7.07378897e-01  2.99923596e-01  6.83546134e-01 -3.27903859e-01\n",
      " -1.61632174e+00 -4.59134034e-01  5.35444650e-01 -2.42415765e-02\n",
      " -2.11093469e+00  1.13729200e+00 -2.18615110e-01 -1.41915394e+00\n",
      "  1.05471443e+00  7.73732546e-01  1.51962734e+00  3.20664439e-02\n",
      "  1.02022850e+00  7.20679583e-01 -1.43171343e+00  3.64504450e-02\n",
      "  1.02255256e+00  1.22401476e+00 -6.07214171e-01  2.21308450e-01\n",
      " -1.62127764e-01  1.87641279e-01 -4.90545488e-01  7.98018501e-02\n",
      " -5.06506505e-01  2.81568354e+00  1.47904659e-02  4.76042790e-01\n",
      "  5.93489607e-01 -1.67968914e+00 -5.52578384e-01 -8.82308308e-01\n",
      "  1.14600221e+00  7.99980526e-01  6.72947630e-01  3.00580778e-01\n",
      "  1.70703598e+00  6.35132330e-01  1.29746866e+00  1.11419982e+00\n",
      "  5.28824047e-02  4.12778128e-01 -1.20911996e+00 -1.17051122e+00]\n"
     ]
    }
   ],
   "source": [
    "arr = np.random.randn(1000)\n",
    "\n",
    "with h5py.File('random.hdf5', 'w') as f:\n",
    "   dset = f.create_dataset(\"default\", (1000,))\n",
    "   dset = arr # wrong\n",
    "   print(dset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   0. ...   0.   0.   0.]\n",
      " [  0.   0.   1. ...   0.   0.   0.]\n",
      " [  0.   0.   0. ...   0.   0.   0.]\n",
      " ...\n",
      " [  0.   0.   0. ... 123. 123. 123.]\n",
      " [  0.   0.   0. ... 123. 123. 123.]\n",
      " [  0.   0.   0. ... 123. 123. 123.]]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('random.hdf5', 'w') as f:\n",
    "    dset = f.create_dataset('default', (500, 1024))\n",
    "    dset[1,2] = 1\n",
    "    dset[200:500, 500:1024] = 123\n",
    "    print(dset[:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specifing datatypes optimize space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('several_datasets.hdf5', 'w') as f:\n",
    "   dset_int_1 = f.create_dataset('integers', (10, ), dtype='i1')\n",
    "   dset_int_8 = f.create_dataset('integers8', (10, ), dtype='i8')\n",
    "   dset_complex = f.create_dataset('complex', (10, ), dtype='c16')\n",
    "\n",
    "   dset_int_1[0] = 1200\n",
    "   dset_int_8[0] = 1200.1\n",
    "   dset_complex[0] = 3 + 4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.randn(100000)\n",
    "\n",
    "f = h5py.File('integer_1.hdf5', 'w')\n",
    "d = f.create_dataset('dataset', (100000,), dtype='i1')\n",
    "d[:] = arr\n",
    "f.close()\n",
    "\n",
    "f = h5py.File('integer_8.hdf5', 'w')\n",
    "d = f.create_dataset('dataset', (100000,), dtype='i8')\n",
    "d[:] = arr\n",
    "f.close()\n",
    "\n",
    "f = h5py.File('float.hdf5', 'w')\n",
    "d = f.create_dataset('dataset', (100000,), dtype='f16')\n",
    "d[:] = arr\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File \tSize (b)\n",
    "\n",
    "integer_1 \t102144\n",
    "\n",
    "integer_8 \t802144\n",
    "\n",
    "float \t1602144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compressing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "arr = np.random.randn(100000)\n",
    "\n",
    "with h5py.File('integer_1_compr.hdf5', 'w') as f:\n",
    "    d = f.create_dataset('dataset', (100000,), dtype='i1', compression=\"gzip\", compression_opts=9)\n",
    "    d[:] = arr\n",
    "\n",
    "with h5py.File('integer_8_compr.hdf5', 'w') as f:\n",
    "    d = f.create_dataset('dataset', (100000,), dtype='i8', compression=\"gzip\", compression_opts=9)\n",
    "    d[:] = arr\n",
    "\n",
    "with h5py.File('float_compr.hdf5', 'w') as f:\n",
    "    d = f.create_dataset('dataset', (100000,), dtype='f16', compression=\"gzip\", compression_opts=9)\n",
    "    d[:] = arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose gzip because it is supported in all platforms. The parameters compression_opts sets the level of compression. The higher the level, the less space data takes but the longer the processor has to work. The default level is 4. We can see the differences in our files based on the level of compression:\n",
    "\n",
    "Type \tNo Compression \tCompression 9 \tCompression 4\n",
    "\n",
    "integer_1 \t102144 \t28016 \t30463\n",
    "\n",
    "integer_8 \t802144 \t43329 \t57971\n",
    "\n",
    "float \t1602144 \t1469580 \t1469868"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resizing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.18844663\n",
      "-1.2919675\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('resize_dataset.hdf5', 'w') as f:\n",
    "    d = f.create_dataset('dataset', (100, ),  maxshape=(500, ))\n",
    "    d[:100] = np.random.randn(100)\n",
    "    d.resize((200,))\n",
    "    d[100:200] = np.random.randn(100)\n",
    "\n",
    "with h5py.File('resize_dataset.hdf5', 'r') as f:\n",
    "    dset = f['dataset']\n",
    "    print(dset[99])\n",
    "    print(dset[199])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you create a dataset to store 100 values and set a maximum size of up to 500 values. After you stored the first batch of values, you can expand the dataset to store the following 100. You can repeat the procedure up to a dataset with 500 values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "-0.70444626\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('resize_dataset.hdf5', 'a') as f:\n",
    "    dset = f['dataset']\n",
    "    dset.resize((300,))\n",
    "    dset[:200] = 0\n",
    "    dset[200:300] = np.random.randn(100)\n",
    "\n",
    "with h5py.File('resize_dataset.hdf5', 'r') as f:\n",
    "    dset = f['dataset']\n",
    "    print(dset[99])\n",
    "    print(dset[199])\n",
    "    print(dset[299])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5py.File('movie_dataset.hdf5', 'w') as f:\n",
    "#    d = f.create_dataset('dataset', (1024, 1024, 1),  maxshape=(1024, 1024, None ))\n",
    "#    d[:,:,0] = first_frame\n",
    "#    d.resize((1024,1024,2))\n",
    "#    d[:,:,1] = second_frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset holds square images of 1024x1024 pixels, while the third dimension gives us the stacking in time. We assume that the images don't change in shape, but we would like to stack one after the other without establishing a limit. This is why we set the third dimension's maxshape to None."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save data in chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('chunked_dataset.hdf5', 'w') as f:\n",
    "    dset = f.create_dataset(\"chunked\", (1000, 1000), chunks=(100, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command means that all the data in dset[0:100,0:100] will be stored together. It is also true for dset[200:300, 200:300], dset[100:200, 400:500], etc. According to h5py, there are some performance implications while using chunks:\n",
    "\n",
    "    Chunking has performance implications. It is recommended to keep the total size of your chunks between 10 KiB and 1 MiB, larger for larger datasets. Also keep in mind that when any element in a chunk is accessed, the entire chunk is read from disk.\n",
    "\n",
    "There is also the possibility of enabling auto-chunking, that will take care of selecting the best size automatically. Auto-chunking is enabled by default if you use compression or maxshape. You enable it explicitly by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 125)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('chunked_dataset.hdf5', 'w') as f:\n",
    "    dset = f.create_dataset(\"chunked\", (1000, 1000), chunks=True)\n",
    "    print(dset.chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Organizing data with groups**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0576639435258907\n",
      "0.0576639435258907\n"
     ]
    }
   ],
   "source": [
    "arr = np.random.randn(1000)\n",
    "\n",
    "with h5py.File('groups.hdf5', 'w') as f:\n",
    "    g = f.create_group('Base_Group')\n",
    "    gg = g.create_group('Sub_Group')\n",
    "\n",
    "    d = g.create_dataset('default', data=arr)\n",
    "    dd = gg.create_dataset('default', data=arr)\n",
    "     \n",
    "with h5py.File('groups.hdf5', 'r') as f:\n",
    "   d = f['Base_Group/default']\n",
    "   dd = f['Base_Group/Sub_Group/default']\n",
    "   print(d[1])\n",
    "   print(dd[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base_Group\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('groups.hdf5', 'r') as f:\n",
    "    for k in f.keys():\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, when you have nested groups, you will also need to start nesting for-loops. There is a better way of iterating through the tree, but it is a bit more involved. We need to use the visit() method, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base_Group\n",
      "Base_Group/Sub_Group\n",
      "Base_Group/Sub_Group/default\n",
      "Base_Group/default\n"
     ]
    }
   ],
   "source": [
    "def get_all(name):\n",
    "   print(name)\n",
    "\n",
    "with h5py.File('groups.hdf5', 'r') as f:\n",
    "   f.visit(get_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we define a function get_all that takes one argument, name. When we use the visit method, it takes as argument a function like get_all. visit will go through each element and while the function doesn't return a value other than None, it will keep iterating. For example, imagine we are looking for an element called Sub_Group we have to change get_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base_Group/Sub_Group\n"
     ]
    }
   ],
   "source": [
    "def get_all(name):\n",
    "    if 'Sub_Group' in name:\n",
    "        return name\n",
    "\n",
    "with h5py.File('groups.hdf5', 'r') as f:\n",
    "    g = f.visit(get_all)\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the method visit is iterating through every element, as soon as the function returns something that is not None it will stop and return the value that get_all generated. Since we are looking for the Sub_Group, we make the get_all return the name of the group when it finds Sub_Group as part of the name that is analyzing. Bear in mind that g is a string, if you want to actually get the group, you should do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('groups.hdf5', 'r') as f:\n",
    "   g_name = f.visit(get_all)\n",
    "   group = f[g_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can work as explained earlier with groups. A second approach is to use a method called visititems that takes a function with two arguments: name and object. We can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First data element: -0.7320548885697936\n"
     ]
    }
   ],
   "source": [
    "def get_objects(name, obj):\n",
    "   if 'Sub_Group' in name:\n",
    "      return obj\n",
    "\n",
    "with h5py.File('groups.hdf5', 'r') as f:\n",
    "   group = f.visititems(get_objects)\n",
    "   data = group['default']\n",
    "   print('First data element: {}'.format(data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference when using visititems is that we have accessed not only the name of the object that is being analyzed but also the object itself. You can see that what the function returns is the object and not the name. This pattern allows you to achieve more complex filtering. For example, you may be interested in the groups that are empty, or that have a specific type of dataset in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Storing metadata**\n",
    "\n",
    "The main difference when using visititems is that we have accessed not only the name of the object that is being analyzed but also the object itself. You can see that what the function returns is the object and not the name. This pattern allows you to achieve more complex filtering. For example, you may be interested in the groups that are empty, or that have a specific type of dataset in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date => 1560235504.3818154\n",
      "User => Me\n",
      "OS => posix\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "arr = np.random.randn(1000)\n",
    "\n",
    "with h5py.File('groups.hdf5', 'w') as f:\n",
    "    g = f.create_group('Base_Group')\n",
    "    d = g.create_dataset('default', data=arr)\n",
    "\n",
    "    g.attrs['Date'] = time.time()\n",
    "    g.attrs['User'] = 'Me'\n",
    "\n",
    "    d.attrs['OS'] = os.name\n",
    "\n",
    "    for k in g.attrs.keys():\n",
    "        print('{} => {}'.format(k, g.attrs[k]))\n",
    "\n",
    "    for j in d.attrs.keys():\n",
    "      print('{} => {}'.format(j, d.attrs[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above you can see that the attrs is like a dictionary. In principle, you shouldn't use attributes to store data, keep them as small as you can. However, you are not limited to single values, you can also store arrays. If you happen to have metadata stored in a dictionary and you want to add it automatically to the attributes, you can use update:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date => 1560235655.6074827\n",
      "User => Me\n",
      "OS => posix\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('groups.hdf5', 'w') as f:\n",
    "   g = f.create_group('Base_Group')\n",
    "   d = g.create_dataset('default', data=arr)\n",
    "\n",
    "   metadata = {'Date': time.time(),\n",
    "      'User': 'Me',\n",
    "      'OS': os.name,}\n",
    "\n",
    "   f.attrs.update(metadata)\n",
    "\n",
    "   for m in f.attrs.keys():\n",
    "      print('{} => {}'.format(m, f.attrs[m]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the data types that hdf5 supports are limited. For example, dictionaries are not supported. If you want to add a dictionary to an hdf5 file you will need to serialize it. In Python, you can serialize a dictionary in different ways. In the example below, we are going to do it with JSON because it is very popular in different fields, but you are free to use whatever you like, including pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with h5py.File('groups_dict.hdf5', 'w') as f:\n",
    "    g = f.create_group('Base_Group')\n",
    "    d = g.create_dataset('default', data=arr)\n",
    "\n",
    "    metadata = {'Date': time.time(),\n",
    "                'User': 'Me',\n",
    "                'OS': os.name,}\n",
    "\n",
    "    m = g.create_dataset('metadata', data=json.dumps(metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
